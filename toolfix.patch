diff --git a/python/sglang/srt/entrypoints/openai/serving_chat.py b/python/sglang/srt/entrypoints/openai/serving_chat.py
index 48197bd78..4af950d62 100644
--- a/python/sglang/srt/entrypoints/openai/serving_chat.py
+++ b/python/sglang/srt/entrypoints/openai/serving_chat.py
@@ -933,14 +933,43 @@ class OpenAIServingChat(OpenAIServingBase):
             if finish_reason["type"] == "stop":
                 finish_reason["type"] = "tool_calls"
                 finish_reason["matched"] = None
+
+            # Prefer FunctionCallParser (DSML detector) when tool_call_parser is configured
+            # This handles DeepSeek-V3.2 and other models that output DSML format
+            if self.tool_call_parser:
+                parser = FunctionCallParser(tools, self.tool_call_parser)
+                if parser.has_tool_call(text):
+                    try:
+                        parsed_text, call_info_list = parser.parse_non_stream(text)
+                        tool_calls = []
+                        for call_info in call_info_list:
+                            tool_id = self._process_tool_call_id(
+                                call_info, history_tool_calls_cnt
+                            )
+                            tool_calls.append(
+                                ToolCall(
+                                    id=tool_id,
+                                    index=getattr(call_info, "tool_index", None),
+                                    function=FunctionResponse(
+                                        name=call_info.name,
+                                        arguments=call_info.parameters,
+                                    ),
+                                )
+                            )
+                        return ToolCallProcessingResult(
+                            tool_calls, parsed_text, finish_reason
+                        )
+                    except Exception as e:
+                        logger.error(f"Tool call parsing error with format detector: {e}")
+                        return ToolCallProcessingResult(None, text, finish_reason)
+
+            # Fallback to JSON parsing if no tool_call_parser configured
             try:
-                # For required tool choice, we expect a JSON array of tool calls
                 tool_call_data = orjson.loads(text)
                 tool_calls = []
                 for i, tool in enumerate(tool_call_data):
-                    # Create a ToolCallItem from the JSON data
                     call_info = ToolCallItem(
-                        tool_index=i,  # Use the loop index as tool_index
+                        tool_index=i,
                         name=tool["name"],
                         parameters=json.dumps(tool["parameters"], ensure_ascii=False),
                     )
@@ -960,8 +989,8 @@ class OpenAIServingChat(OpenAIServingBase):
                         )
                     )
                 return ToolCallProcessingResult(tool_calls, "", finish_reason)
-            except json.JSONDecodeError as e:
-                logger.error(f"Tool call parsing error: {e}")
+            except (json.JSONDecodeError, orjson.JSONDecodeError, TypeError, KeyError) as e:
+                logger.error(f"Tool call JSON parsing error: {e}")
                 return ToolCallProcessingResult(None, text, finish_reason)
 
         # Use parser since output is not constrained by JSON schema
@@ -1085,11 +1114,21 @@ class OpenAIServingChat(OpenAIServingBase):
     ):
         """Process tool calls in streaming response"""
         if index not in parser_dict:
-            # Use JSON detector directly for required or named tool choice
+            # Use JSON detector directly for required or named tool choice,
+            # but prefer FunctionCallParser if tool_call_parser is configured
+            # (handles cases where model outputs DSML format instead of JSON)
             if request.tool_choice == "required" or isinstance(
                 request.tool_choice, ToolChoice
             ):
-                parser_dict[index] = JsonArrayParser()
+                if self.tool_call_parser:
+                    # Prefer FunctionCallParser (DSML detector) when configured
+                    # This handles DeepSeek-V3.2 and other models that output DSML format
+                    parser_dict[index] = FunctionCallParser(
+                        tools=request.tools,
+                        tool_call_parser=self.tool_call_parser,
+                    )
+                else:
+                    parser_dict[index] = JsonArrayParser()
             else:
                 parser_dict[index] = FunctionCallParser(
                     tools=request.tools,
